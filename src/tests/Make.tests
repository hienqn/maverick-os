# -*- makefile -*-
# =============================================================================
# PintOS Test Infrastructure (Make.tests)
# =============================================================================
# Central test running system. Handles:
#   - Building test programs
#   - Running tests in QEMU/Bochs
#   - Checking output against expected results
#   - Generating grade reports
#
# ARCHITECTURE SUPPORT:
# --------------------
# - i386:    Uses QEMU with IDE disks, loader.bin for boot
# - riscv64: Uses QEMU with OpenSBI firmware, VirtIO devices, no loader needed
#
# Usage:
#   make check                    # i386 (default)
#   make check ARCH=riscv64       # RISC-V
#   make grade                    # Generate detailed grade report
# =============================================================================

# For RISC-V, skip user programs until user mode is fully ported
ifeq ($(ARCH),riscv64)
TEST_SUBDIRS := $(filter-out tests/userprog tests/userprog/kernel tests/userprog/multithreading tests/filesys/base,$(TEST_SUBDIRS))
endif

# Include test definitions from each test subdirectory
# Each Make.tests file defines:
#   - <subdir>_PROGS: Test programs to build
#   - <subdir>_TESTS: Tests to run
include $(patsubst %,$(SRCDIR)/%/Make.tests,$(TEST_SUBDIRS))

# =============================================================================
# Special Compilation Rules
# =============================================================================

# Stack alignment tests must use clang, not gcc (i386 only).
# GCC defensively auto-aligns the stack in main(), which would make these
# tests pass even if the kernel doesn't properly align the stack.
# See: https://stackoverflow.com/questions/40307193
ifeq ($(ARCH),i386)
tests/userprog/stack-align.o: tests/userprog/stack-align.c
	clang -target i386-pc-linux-elf  -m32 -c $< -o $@ $(CFLAGS) $(CPPFLAGS) -I$(SRCDIR)/lib/user -I. -fomit-frame-pointer $(WARNINGS) $(DEFINES) $(DEPS)
endif

ifeq ($(ARCH),i386)
tests/userprog/stack-align-0.o: tests/userprog/stack-align-0.c
	$(CC) -m32 -c $< -o $@ $(CFLAGS) $(CPPFLAGS) -I$(SRCDIR)/lib/user -I. -fomit-frame-pointer $(WARNINGS) $(DEFINES) $(DEPS)

# dir-vine needs optimization to avoid stack overflow from deep recursion
tests/filesys/extended/dir-vine.o: tests/filesys/extended/dir-vine.c
	$(CC) -m32 -c $< -o $@ $(subst -O0,-O1,$(CFLAGS)) $(CPPFLAGS) $(WARNINGS) $(DEFINES) $(DEPS)
endif

# =============================================================================
# Test Collection
# =============================================================================

# Collect all programs, tests, and extra grade items from all test subdirs
PROGS = $(foreach subdir,$(TEST_SUBDIRS),$($(subdir)_PROGS))
TESTS = $(foreach subdir,$(TEST_SUBDIRS),$($(subdir)_TESTS))
EXTRA_GRADES = $(foreach subdir,$(TEST_SUBDIRS),$($(subdir)_EXTRA_GRADES))

# Generated files for each test
OUTPUTS = $(addsuffix .output,$(TESTS) $(EXTRA_GRADES))
ERRORS = $(addsuffix .errors,$(TESTS) $(EXTRA_GRADES))
RESULTS = $(addsuffix .result,$(TESTS) $(EXTRA_GRADES))

# Include user program build rules if there are programs to build
ifdef PROGS
include ../../Makefile.userprog
endif

# Default timeout for each test (seconds)
# Most tests complete in <10s; 30s is plenty for slower ones
TIMEOUT = 30

# =============================================================================
# Test Targets
# =============================================================================

# Clean test artifacts
clean::
	rm -f $(OUTPUTS) $(ERRORS) $(RESULTS)

# Generate detailed grade report using grading rubric
grade:: results
	$(SRCDIR)/tests/make-grade $(SRCDIR) $< $(GRADING_FILE) | tee $@

# Run all tests and show summary
# Counts passes and failures, exits with error if any tests failed
check:: results
	@cat $<
	@COUNT="`egrep '^(pass|FAIL) ' $< | wc -l | sed 's/[ 	]//g;'`"; \
	FAILURES="`egrep '^FAIL ' $< | wc -l | sed 's/[ 	]//g;'`"; \
	if [ $$FAILURES = 0 ]; then					  \
		echo "All $$COUNT tests passed.";			  \
	else								  \
		echo "$$FAILURES of $$COUNT tests failed.";		  \
		exit 1;							  \
	fi

# Aggregate all .result files into a single results file
# Compares each .result to "PASS" to determine pass/fail
results: $(RESULTS)
	@for d in $(TESTS) $(EXTRA_GRADES); do			\
		if echo PASS | cmp -s $$d.result -; then	\
			echo "pass $$d";			\
		else						\
			echo "FAIL $$d";			\
		fi;						\
	done > $@

# Build all test outputs (useful for debugging)
outputs:: $(OUTPUTS)

# =============================================================================
# Dynamic Rule Generation
# =============================================================================
# These $(eval) calls generate rules at parse time for each test

# Each program's output depends on the program binary
$(foreach prog,$(PROGS),$(eval $(prog).output: $(prog)))

# Each test's output depends on files that need to be copied to the VM
$(foreach test,$(TESTS),$(eval $(test).output: $($(test)_PUTFILES)))

# Set TEST variable for each test's output rule
$(foreach test,$(TESTS),$(eval $(test).output: TEST = $(test)))

# Each result depends on output and checker script (.ck file)
$(foreach test,$(TESTS),$(eval $(test).result: $(test).output $(test).ck))

# =============================================================================
# Test Execution Command
# =============================================================================

# Prevent environment variable from affecting build
VERBOSE =

# Command to run inside PintOS (default: "run")
RUNCMD = run

# Build the pintos command line piece by piece
# -v: verbose; -k: kill on kernel panic
# --gdb or -T: either enable GDB or set timeout
# Note: $(PINTOS) is defined in Make.config (supports USE_BUN=1 toggle)
TESTCMD = $(PINTOS) -v -k $(if ${PINTOS_DEBUG},--gdb,-T $(TIMEOUT))

# Pass architecture to pintos script
ifneq ($(ARCH),)
TESTCMD += --arch=$(ARCH)
endif

# Simulator selection (can be overridden with FORCE_SIMULATOR)
TESTCMD += $(or ${FORCE_SIMULATOR},$(SIMULATOR))

# Additional pintos options
TESTCMD += $(PINTOSOPTS)

# If userprog is enabled, set up filesystem and copy test files
ifeq ($(filter userprog, $(KERNEL_SUBDIRS)), userprog)
TESTCMD += $(FILESYSSOURCE)
TESTCMD += $(foreach file,$(PUTFILES),-p $(file) -a $(notdir $(file)))
endif

# If VM is enabled, add swap space (unless test disables it)
ifeq ($(filter vm, $(KERNEL_SUBDIRS)), vm)
# Add swap unless the test has _NO_SWAP set (e.g., for multi-oom OOM testing)
# Skip for RISC-V until disk infrastructure is fully ported
# Use $(if ...) instead of ifeq because TEST is a target-specific variable
# that's only available at build time, not parse time
ifneq ($(ARCH),riscv64)
TESTCMD += $(if $($(TEST)_NO_SWAP),,--swap-size=4)
endif
endif

# Separator between pintos options and kernel arguments
TESTCMD += -- -q

# Kernel flags and test-specific arguments
TESTCMD += $(KERNELFLAGS)
TESTCMD += $($(TEST)_KERNELARGS)

# Format filesystem if userprog is enabled
ifeq ($(filter userprog, $(KERNEL_SUBDIRS)), userprog)
TESTCMD += -f
endif

# Run the test: either with arguments or just the test name
# $(*F) extracts just the filename from the test path
TESTCMD += $(if $($(TEST)_ARGS),$(RUNCMD) '$(*F) $($(TEST)_ARGS)',$(RUNCMD) $(*F))

# Redirect stdin/stdout unless debugging
TESTCMD += $(if ${PINTOS_DEBUG},,< /dev/null)
TESTCMD += $(if ${PINTOS_DEBUG},,2> $(TEST).errors $(if $(VERBOSE),|tee,>) $(TEST).output)

# =============================================================================
# Pattern Rules
# =============================================================================

# Run a test: requires kernel and loader binaries
# RISC-V doesn't use loader.bin (OpenSBI handles boot)
ifeq ($(ARCH),riscv64)
%.output: kernel.bin
	$(TESTCMD)
else
%.output: kernel.bin loader.bin
	$(TESTCMD)
endif

# Check test output against expected results
# $< = checker script (.ck), $* = test name (stem)
# Note: $(CHECK_TEST) is defined in Make.config (supports USE_BUN=1 toggle)
%.result: %.ck %.output
	$(CHECK_TEST) $< $* $@
